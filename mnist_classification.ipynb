{"cells":[{"cell_type":"markdown","metadata":{"id":"-AxfT2TjSQ2g"},"source":["# MNIST Classification"]},{"cell_type":"markdown","metadata":{"id":"3Tbt1ynnSQ2i"},"source":["üéØ <b><u>Exercise objectives</u></b>\n","- Understand the *MNIST* dataset\n","- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n","    - what are *Convolutional Layers*?\n","    - how many *parameters* are involved in such a layer?\n","- Train this CNN on images"]},{"cell_type":"markdown","metadata":{"id":"p-prQrukSQ2j"},"source":["üöÄ <b><u>Let's get started!</u></b>\n","\n","Imagine that we are  back in time into the 90's.\n","You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits?\n","\n","This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n","\n","From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n","\n","> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"]},{"cell_type":"code","source":["!git config --global user.email 'pp085ster@gmail.com'\n","!git add mnist_classification.ipynb\n","!git commit -m 'testing uploading to git from Google Colab'\n","!git push origin master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTGWu9XlSSxu","executionInfo":{"status":"ok","timestamp":1708513346073,"user_tz":-60,"elapsed":1383,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"52461a9d-2ae5-43f9-9a93-751d91acdf4f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[master 57aeff2] testing uploading to git from Google Colab\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite mnist_classification.ipynb (89%)\n","Host key verification failed.\n","fatal: Could not read from remote repository.\n","\n","Please make sure you have the correct access rights\n","and the repository exists.\n"]}]},{"cell_type":"code","source":["pip install nbresult"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O42VJnobS0o-","executionInfo":{"status":"ok","timestamp":1708513281220,"user_tz":-60,"elapsed":7115,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"e3e9c78c-a651-4923-ed88-a6aa8ad637f8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nbresult\n","  Downloading nbresult-0.0.9-py3-none-any.whl (4.3 kB)\n","Installing collected packages: nbresult\n","Successfully installed nbresult-0.0.9\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQjx4SSHSeZR","executionInfo":{"status":"ok","timestamp":1708513476614,"user_tz":-60,"elapsed":2476,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"8b46ad9f-34ca-4a34-b669-7beb1b793168"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Le Wagon/data-mnist-classification\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJUK9L6yTj9w","executionInfo":{"status":"ok","timestamp":1708513270323,"user_tz":-60,"elapsed":849,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"60027908-d3fa-4705-c63f-40c4623869dc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Le Wagon/data-mnist-classification\n","mnist_classification.ipynb  README.md  recognition.gif\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ke6bFE5sSQ2k"},"source":["![Number recognition](recognition.gif)\n","\n","*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"]},{"cell_type":"markdown","metadata":{"id":"yk8LUrv7SQ2l"},"source":["ü§î <b><u>How does this CNN work ?</u></b>\n","\n","- *Inputs*: Images (_each image shows a handwritten digit_)\n","- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n","    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n","\n","üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"5Bv_W8epSQ2l","executionInfo":{"status":"ok","timestamp":1708513555981,"user_tz":-60,"elapsed":593,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"Dx-98l7wSQ2m"},"source":["## (1) The `MNIST` Dataset"]},{"cell_type":"markdown","metadata":{"id":"IJYObzMvSQ2n"},"source":["üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n","- *Vectors*: `boston_housing` (regression)\n","- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n","- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n","\n","\n","üíæ You can **load the MNIST dataset** with the following commands:"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kq96HQlSQ2n","executionInfo":{"status":"ok","timestamp":1708513590889,"user_tz":-60,"elapsed":5134,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"5f560104-f866-4a0c-934d-b7daf80319ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]},{"output_type":"execute_result","data":{"text/plain":["(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"]},"metadata":{},"execution_count":9}],"source":["from tensorflow.keras import datasets\n","\n","\n","# Loading the MNIST Dataset...\n","(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n","\n","# The train set contains 60 000 images, each of them of size 28x28\n","# The test set contains 10 000 images, each of them of size 28x28\n","(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"A74eN8FTSQ2o"},"source":["### (1.1) Exploring the dataset"]},{"cell_type":"markdown","metadata":{"id":"arEpaQpISQ2p"},"source":["‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n","\n","üñ® Print some images from the *train set*.\n","\n","<details>\n","    <summary><i>Hints</i></summary>\n","\n","üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n","\n","ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n","    \n","</details>"]},{"cell_type":"code","execution_count":12,"metadata":{"tags":["challengify"],"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HeNYeh9uSQ2p","executionInfo":{"status":"ok","timestamp":1708513648811,"user_tz":-60,"elapsed":7,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"b615bfac-8fde-4cc3-829c-b37362568879"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  56, 105,\n","        220, 254,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 166, 233, 253,\n","        253, 253, 236, 209, 209, 209,  77,  18,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 253, 253, 253,\n","        253, 253, 254, 253, 253, 253, 253, 172,   8,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  57, 238, 253, 253, 253,\n","        253, 253, 254, 253, 253, 253, 253, 253, 119,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  14, 238, 253, 253, 253, 253,\n","        253, 253, 179, 196, 253, 253, 253, 253, 238,  12,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  33, 253, 253, 253, 253, 253,\n","        248, 134,   0,  18,  83, 237, 253, 253, 253,  14,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0, 164, 253, 253, 253, 253, 253,\n","        128,   0,   0,   0,   0,  57, 119, 214, 253,  94,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  57, 248, 253, 253, 253, 126,  14,\n","          4,   0,   0,   0,   0,   0,   0, 179, 253, 248,  56,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 175, 253, 253, 240, 190,  28,   0,\n","          0,   0,   0,   0,   0,   0,   0, 179, 253, 253, 173,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 209, 253, 253, 178,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,  92, 253, 253, 208,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 211, 254, 254, 179,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0, 135, 255, 209,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 209, 253, 253,  90,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0, 134, 253, 208,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 209, 253, 253, 178,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   2, 142, 253, 208,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 209, 253, 253, 214,  35,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,  30, 253, 253, 208,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 165, 253, 253, 253, 215,  36,   0,\n","          0,   0,   0,   0,   0,   0,   0, 163, 253, 253, 164,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  18, 172, 253, 253, 253, 214, 127,\n","          7,   0,   0,   0,   0,   0,  72, 232, 253, 171,  17,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   8, 182, 253, 253, 253, 253,\n","        162,  56,   0,   0,   0,  64, 240, 253, 253,  14,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   7, 173, 253, 253, 253,\n","        253, 245, 241, 239, 239, 246, 253, 225,  14,   1,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  18,  59, 138, 224,\n","        253, 253, 254, 253, 253, 253, 240,  96,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37,\n","        104, 192, 255, 253, 253, 182,  73,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"],"text/html":["<style>\n","      .ndarray_repr .ndarray_raw_data {\n","        display: none;\n","      }\n","      .ndarray_repr.show_array .ndarray_raw_data {\n","        display: block;\n","      }\n","      .ndarray_repr.show_array .ndarray_image_preview {\n","        display: none;\n","      }\n","      </style>\n","      <div id=\"id-63784415-78d0-411a-b598-83c07ccd8b5e\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABDUlEQVR4nM3RsUrDUBTG8S9BaAcJmLmLWPEVUhx01MFJBwcRR50cu6mLDn0MER1sEYx0FAcfwEDp5KCbgrZxULL8E4e05t6a0cEz3Y8f957DudI/rmDvMV0qJ//8FXiLomjN/4UbAKQA7eqENQYF0rTNy43wHmAwbeEsAMmJ/PV3wLPwDIAjSWo0+2xbHRPgwJvKU0gSGHgF8W1tnELoGBjBdZG24EGS3Dy6juMYA7RcR5JGXdJMF8ZDWZoZNyVtFuaONlRgfe7nWNu3sCct3NTHeCz1jCZ+G+gfViRJKy9czhioahfgNJC0HE+uT5UOwOfHcPjFs+fYKH+x9ZR/Wbyjkprfvcugu1pmf1jfxNKPOOys5PsAAAAASUVORK5CYII=\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  56, 105,\n","        220, 254,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 166, 233, 253,\n","        253, 253, 236, 209, 209, 209,  77,  18,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 253, 253, 253,\n","        253, 253, 254, 253, 253, 253, 253, 172,   8,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  57, 238, 253, 253, 253,\n","        253, 253, 254, 253, 253, 253, 253, 253, 119,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  14, 238, 253, 253, 253, 253,\n","        253, 253, 179, 196, 253, 253, 253, 253, 238,  12,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  33, 253, 253, 253, 253, 253,\n","        248, 134,   0,  18,  83, 237, 253, 253, 253,  14,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0, 164, 253, 253, 253, 253, 253,\n","        128,   0,   0,   0,   0,  57, 119, 214, 253,  94,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  57, 248, 253, 253, 253, 126,  14,\n","          4,   0,   0,   0,   0,   0,   0, 179, 253, 248,  56,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 175, 253, 253, 240, 190,  28,   0,\n","          0,   0,   0,   0,   0,   0,   0, 179, 253, 253, 173,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 209, 253, 253, 178,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,  92, 253, 253, 208,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 211, 254, 254, 179,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0, 135, 255, 209,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 209, 253, 253,  90,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0, 134, 253, 208,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 209, 253, 253, 178,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   2, 142, 253, 208,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 209, 253, 253, 214,  35,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,  30, 253, 253, 208,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 165, 253, 253, 253, 215,  36,   0,\n","          0,   0,   0,   0,   0,   0,   0, 163, 253, 253, 164,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  18, 172, 253, 253, 253, 214, 127,\n","          7,   0,   0,   0,   0,   0,  72, 232, 253, 171,  17,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   8, 182, 253, 253, 253, 253,\n","        162,  56,   0,   0,   0,  64, 240, 253, 253,  14,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   7, 173, 253, 253, 253,\n","        253, 245, 241, 239, 239, 246, 253, 225,  14,   1,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  18,  59, 138, 224,\n","        253, 253, 254, 253, 253, 253, 240,  96,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37,\n","        104, 192, 255, 253, 253, 182,  73,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)</pre></div><script>\n","      (() => {\n","      const titles = ['show data', 'hide data'];\n","      let index = 0\n","      document.querySelector('#id-63784415-78d0-411a-b598-83c07ccd8b5e button').onclick = (e) => {\n","        document.querySelector('#id-63784415-78d0-411a-b598-83c07ccd8b5e').classList.toggle('show_array');\n","        index = (++index) % 2;\n","        document.querySelector('#id-63784415-78d0-411a-b598-83c07ccd8b5e button').textContent = titles[index];\n","        e.preventDefault();\n","        e.stopPropagation();\n","      }\n","      })();\n","    </script>"]},"metadata":{},"execution_count":12}],"source":["# YOUR CODE HERE\n","X_train[56]"]},{"cell_type":"markdown","metadata":{"id":"ixrxidwzSQ2q"},"source":["### (1.2) Image Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"SvRxVrqMSQ2q"},"source":["‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n","\n","üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n","* The `RBG` intensities are coded between 0 and 255.\n","* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"]},{"cell_type":"markdown","metadata":{"id":"eMYviKc0SQ2q"},"source":["‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.**\n","\n","Don't forget to do it both on your train data and your test data.\n","\n","(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"]},{"cell_type":"code","execution_count":17,"metadata":{"tags":["challengify"],"id":"LBsf8IA4SQ2q","executionInfo":{"status":"ok","timestamp":1708513895144,"user_tz":-60,"elapsed":3,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}}},"outputs":[],"source":["# YOUR CODE HERE\n","X_train = X_train/255\n","X_test = X_test/255"]},{"cell_type":"markdown","metadata":{"id":"jPP_fmheSQ2r"},"source":["### (1.3) Inputs' dimensionality"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHRFtxIUSQ2r","executionInfo":{"status":"ok","timestamp":1708513761627,"user_tz":-60,"elapsed":4,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"13a560d4-251d-4d52-fc67-57d41aa2c6d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 28, 28)\n","(10000, 28, 28)\n"]}],"source":["print(X_train.shape)\n","print(X_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"HnnWyxm3SQ2s"},"source":["üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n","\n","> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n","\n","> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n","\n","üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n","<br>\n","<details>\n","    <summary><i>Answer<i></summary>\n","        \n","* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n","        \n","    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n","        \n","    * In comparison, colored pictures need multiple channels:\n","        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n","        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n","        \n","        \n","</details>        "]},{"cell_type":"markdown","metadata":{"id":"Wft64Ke3SQ2s"},"source":["‚ùì **Question: expanding dimensions** ‚ùì\n","\n","* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n","\n","* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"eaKxQzfPSQ2s","executionInfo":{"status":"ok","timestamp":1708513881348,"user_tz":-60,"elapsed":565,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}}},"outputs":[],"source":["from tensorflow.keras.backend import expand_dims"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"AI1Pa4ftSQ2s","executionInfo":{"status":"ok","timestamp":1708513995423,"user_tz":-60,"elapsed":2233,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}}},"outputs":[],"source":["X_train = expand_dims(X_train)\n","X_test = expand_dims(X_test)"]},{"cell_type":"code","source":["X_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84jqWDaLXrWa","executionInfo":{"status":"ok","timestamp":1708514086656,"user_tz":-60,"elapsed":4,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"2a00dd30-7dce-4b2c-d464-895b14f1c85e"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([10000, 28, 28, 1])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"3XYrpMvtSQ2s"},"source":["### (1.4) Target encoding"]},{"cell_type":"markdown","metadata":{"id":"A84AkNqLSQ2t"},"source":["One more thing to do for a multiclass classification task in Deep Leaning:\n","\n","üëâ _\"one-hot-encode\" the categories*_\n","\n","‚ùì **Question: encoding the labels** ‚ùì\n","\n","* Use **`to_categorical`** to transform your labels.\n","* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"dR880gD4SQ2t","executionInfo":{"status":"ok","timestamp":1708514204095,"user_tz":-60,"elapsed":335,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}}},"outputs":[],"source":["from tensorflow.keras.utils import to_categorical\n","\n","y_train_cat = to_categorical(y_train, 10)\n","y_test_cat = to_categorical(y_test, 10)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"z8QEkB72SQ2t","executionInfo":{"status":"ok","timestamp":1708514218535,"user_tz":-60,"elapsed":582,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}}},"outputs":[],"source":["# Quick check that you correctly used to_categorical\n","assert(y_train_cat.shape == (60000,10))\n","assert(y_test_cat.shape == (10000,10))"]},{"cell_type":"markdown","metadata":{"id":"nARoYGyzSQ2t"},"source":["The data is now ready to be used. ‚úÖ"]},{"cell_type":"markdown","metadata":{"id":"UeTRcc2lSQ2u"},"source":["## (2) The Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"jsGaHAJXSQ2u"},"source":["### (2.1) Architecture and compilation of a CNN"]},{"cell_type":"markdown","metadata":{"id":"8qli-tvNSQ2u"},"source":["\n","‚ùì **Question: CNN Architecture and compilation** ‚ùì\n","\n","Now, let's build a <u>Convolutional Neural Network</u> that has:\n","\n","\n","- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n","- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n","- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n","- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n","\n","\n","- a `Flatten` layer\n","- a first `Dense` layer with 10 neurons and the `relu` activation function\n","- a last (predictive) layer that is suited for your task\n","\n","In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n","* optimizes the `categorical_crossentropy` loss function,\n","* with the `adam` optimizer,\n","* and the `accuracy` as the metrics\n","\n","(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"71DJD87OSQ2u","executionInfo":{"status":"ok","timestamp":1708514915317,"user_tz":-60,"elapsed":580,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}}},"outputs":[],"source":["from tensorflow.keras import layers\n","from tensorflow.keras import models\n","\n","\n","def initialize_model():\n","\n","    model = models.Sequential()\n","\n","    ### First Convolution & MaxPooling\n","    model.add(layers.Conv2D(8, 4, activation='relu', input_shape=(28, 28, 1), padding='same'))\n","    model.add(layers.MaxPool2D(pool_size=(2,2)))\n","\n","    ### Second Convolution & MaxPooling\n","    model.add(layers.Conv2D(16, 3, activation='relu'))\n","    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n","\n","    ### Flattening\n","    model.add(layers.Flatten())\n","\n","    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n","    model.add(layers.Dense(10, activation='relu'))\n","\n","    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n","    model.add(layers.Dense(10, activation='softmax'))\n","\n","    ### Model compilation\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"eVIKfASESQ2u"},"source":["‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì\n","\n","How many trainable parameters are there in your model?\n","1. Compute them with ***model.summary( )*** first\n","2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."]},{"cell_type":"code","execution_count":28,"metadata":{"tags":["challengify"],"colab":{"base_uri":"https://localhost:8080/"},"id":"JNvGDWRxSQ2v","executionInfo":{"status":"ok","timestamp":1708514944619,"user_tz":-60,"elapsed":407,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"5dd5568b-7336-47ed-8772-800c391128d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 28, 28, 8)         136       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 14, 14, 8)         0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 12, 12, 16)        1168      \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 6, 6, 16)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 576)               0         \n","                                                                 \n"," dense (Dense)               (None, 10)                5770      \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                110       \n","                                                                 \n","=================================================================\n","Total params: 7184 (28.06 KB)\n","Trainable params: 7184 (28.06 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# YOUR CODE HERE\n","model = initialize_model()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"PotPgPEISQ2v"},"source":["### (2.2) Training a CNN"]},{"cell_type":"markdown","metadata":{"id":"rEfUUZRySQ2v"},"source":["‚ùì **Question: training a CNN** ‚ùì\n","\n","Initialize your model and fit it on the train data.\n","- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**.\n","- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"HZypddXwSQ2w","executionInfo":{"status":"ok","timestamp":1708515691915,"user_tz":-60,"elapsed":31205,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}}},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","es = EarlyStopping(patience=20, restore_best_weights=True)\n","history = model.fit(X_train, y_train_cat, validation_split=0.3, batch_size=32, epochs=5, verbose=0, callbacks=[es])"]},{"cell_type":"code","source":["history.history"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dstvbPNgdat1","executionInfo":{"status":"ok","timestamp":1708515691915,"user_tz":-60,"elapsed":5,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"34982648-18c9-4101-a306-6fe5d2c0f90e"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'loss': [0.051495261490345,\n","  0.044460929930210114,\n","  0.0400150828063488,\n","  0.03732558712363243,\n","  0.03210721164941788],\n"," 'accuracy': [0.9838571548461914,\n","  0.9855714440345764,\n","  0.9872381091117859,\n","  0.9879047870635986,\n","  0.9893571138381958],\n"," 'val_loss': [0.06271194666624069,\n","  0.06137852743268013,\n","  0.05779774859547615,\n","  0.07291026413440704,\n","  0.057556699961423874],\n"," 'val_accuracy': [0.9812777638435364,\n","  0.9823333621025085,\n","  0.9828888773918152,\n","  0.9803333282470703,\n","  0.9835555553436279]}"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"6EEO8q2SSQ2w"},"source":["‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n","\n","_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"]},{"cell_type":"markdown","metadata":{"tags":["challengify"],"id":"koZSSIy6SQ2w"},"source":["> YOUR ANSWER HERE"]},{"cell_type":"markdown","metadata":{"id":"Emcqnx4hSQ2w"},"source":["<details>\n","    <summary><i>Answer</i></summary>\n","\n","With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n","    \n","Remember that we've just trained our CNN model on $60000$ training images\n","\n","If the chosen batch size is 32:\n","\n","* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n","* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n","    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss`\n","    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n","    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n","\n","\n","üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n","\n","</details>    \n"]},{"cell_type":"markdown","metadata":{"id":"2fHfzSMCSQ2x"},"source":["### (2.3) Evaluating its performance"]},{"cell_type":"markdown","metadata":{"id":"WQ4O5ZjiSQ2x"},"source":["‚ùì **Question: Evaluating your CNN** ‚ùì\n","\n","What is your **`accuracy on the test set?`**"]},{"cell_type":"code","execution_count":34,"metadata":{"tags":["challengify"],"colab":{"base_uri":"https://localhost:8080/"},"id":"A2jZ3leGSQ2x","executionInfo":{"status":"ok","timestamp":1708515773090,"user_tz":-60,"elapsed":1412,"user":{"displayName":"Pablo Pussell","userId":"17647573941284887369"}},"outputId":"01d2d615-4ec6-4e7c-fdce-f9b7ca6aab02"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.0440 - accuracy: 0.9868\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.044036053121089935, 0.9868000149726868]"]},"metadata":{},"execution_count":34}],"source":["# YOUR CODE HERE\n","results = model.evaluate(X_test, y_test_cat, batch_size=32)\n","results"]},{"cell_type":"markdown","metadata":{"id":"sTnvJsg1SQ2y"},"source":["üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n","\n","üî• You solved what was a very hard problem 30 years ago with your own CNN."]},{"cell_type":"markdown","metadata":{"id":"d9WGkhqbSQ2y"},"source":["üèÅ **Congratulations!**\n","\n","üíæ Don't forget to `git add/commit/push` your notebook...\n","\n","üöÄ ... and move on to the next challenge!"]},{"cell_type":"code","source":["!git add mnist_classification.ipynb\n","!git commit -m ''"],"metadata":{"id":"AQw0t3jBeicL"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}